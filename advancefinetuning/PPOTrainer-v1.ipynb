{"cells":[{"cell_type":"markdown","id":"9ad55e34-43df-4677-8946-18913a8cf67f","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"5d77bc16-41cd-4d1f-b5e5-e99bfd8045b6","metadata":{},"source":["# Reinforcement Learning from Human Feedback Using PPO\n"]},{"cell_type":"markdown","id":"57bcdddd-4157-4d68-8956-e0447edae66e","metadata":{},"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","id":"7af34e09-1271-4af2-9cc4-9cd39076055f","metadata":{},"source":["\n","Imagine you are an AI engineer who wants to train a \"Happy LLM\" and a \"Pessimistic LLM\" to train customer service agents. You have a reward function trained on the sentiment classifier from the IMDb dataset, and you will now use Reinforcement Learning (RL). RL is a subfield of machine learning where an agent learns to make decisions by performing actions in an environment to maximize a cumulative reward. The agent, in this case, will be the LLM, and the decisions will be about what text to output. Unlike supervised learning, which requires labeled input/output pairs, RL relies on the agent exploring the environment and learning from the feedback it receives in the form of rewards or penalties. This trial-and-error approach enables the agent to improve its decision-making strategy over time.\n","\n","Proximal Policy Optimization (PPO) is one of the most effective and widely used RL algorithms. Introduced by OpenAI, PPO strikes a balance between simplicity and performance, making it a popular choice for training RL agents. PPO optimizes the policy directly and employs mechanisms to ensure the updates are not too drastic, thereby maintaining stability and reliability during training.\n","\n","In this lab, you will be guided through the process of training an RL agent using the PPO algorithm with a focus on sentiment analysis. You will use the IMDb dataset, a large collection of movie reviews, to train your model. By the end of this lab, you will have a solid understanding of how to implement and train an RL agent using PPO, and you will be equipped with practical skills to apply RL techniques to other problems and datasets.\n","This lab is based on [a HF example code titled `Tune GPT2 to generate positive reviews`](https://github.com/huggingface/trl/blob/main/examples/notebooks/gpt2-sentiment.ipynb).\n"]},{"cell_type":"markdown","id":"7e7e4c33-7c4e-4331-96a2-af0537d3cb08","metadata":{},"source":["## __Table of Contents__\n","\n","<ol>\n","    <li><a href=\"#Objectives\">Objectives</a></li>\n","    <li>\n","        <a href=\"#Setup\">Setup</a>\n","        <ol>\n","            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n","            <li><a href=\"#Importing-required-libraries\">Importing required libraries</a></li>\n","            <li><a href=\"#Defining-helper-functions\">Defining helper functions</a></li>\n","        </ol>\n","    </li>\n","    <li><a href=\"#Initializing-the-PPO-configuration,-model,-and-tokenizer\">Initializing the PPO configuration, model, and tokenizer</a></li>\n","            <li><a href=\"#Dataset-and-dataset-tokenization\">Dataset and dataset tokenization</a></li>\n","            <li><a href=\"#Collator-function\">Collator function</a></li>\n","            <li><a href=\"#Initialize-PPOTrainer\">Initialize PPOTrainer</a></li>\n","            <li><a href=\"#Reward-function\">Reward function</a></li>\n","    <li>\n","        <a href=\"#Generating-responses-using-PPO\">Generating responses using PPO</a>\n","        <ol>\n","            <li><a href=\"#Tokenizing-and-preparing-the-input-batch\">Tokenizing and preparing the input batch</a></li>\n","            <li><a href=\"#Scoring-function\">Scoring function</a></li>\n","            <li><a href=\"#Proximal-policy-optimization\">Proximal policy optimization</a></li>\n","        </ol>\n","    </li>\n","    <li><a href=\"#Plotting-PPO-training-loss-and-mean\">Plotting PPO training loss and mean</a></li>\n","    <li><a href=\"#Generating-and-analyzing-text-with-PPO-and-reference-models\">Generating and analyzing text with PPO and reference models</a></li>\n","    <li>\n","        <a href=\"#Comparing-PPO-and-reference-models-on\">Comparing PPO and reference models on</a>\n","        <ol>\n","        </ol>\n","    </li>\n","                <li><a href=\"#Running-the-PPO-model-with-negative-sentiment\">Running the PPO model with negative sentiment</a></li>\n","            <li><a href=\"#Comparing-models-with-negative-sentiment\">Comparing models with negative sentiment</a></li>\n","            <li><a href=\"#Exercise:-Comparing-PPO-models\">Exercise: Comparing PPO models</a></li>\n","</ol>\n"]},{"cell_type":"markdown","id":"7be0e79a-e64c-4679-98ea-1c7d0b3b9b3d","metadata":{},"source":["## Objectives\n","\n","After completing this lab you will be able to:\n","\n","- Apply the basics of reinforcement learning and proximal policy optimization (PPO).\n","- Set up the environment and load the IMDb dataset for training.\n","- Define and configure the PPO agent and tokenizer.\n","- Implement the PPO training loop.\n","- Generate and evaluate text responses from the trained model.\n","- Compare the performance of two models on the dataset.\n","- Save and load the trained model for future use.\n"]},{"cell_type":"markdown","id":"7eca9dd8-41a4-447f-86ef-1a7dc91a426d","metadata":{},"source":["----\n"]},{"cell_type":"markdown","id":"b0b8b7d0-5f98-475b-9911-2a0327733d5a","metadata":{},"source":["## Setup\n"]},{"cell_type":"markdown","id":"d461a42a-37be-4504-986a-2e45c3439a7f","metadata":{},"source":["For this lab, you will use the following libraries:\n","\n","*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n","*   [`torch`](https://pytorch.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for tensor operations and model training.\n","*   [`tqdm`](https://tqdm.github.io/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for progress bars.\n","*   [`transformers`](https://huggingface.co/transformers/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for pretrained language models.\n","*   [`datasets`](https://huggingface.co/docs/datasets/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for loading and processing datasets.\n","*   [`trl`](https://github.com/lvwerra/trl/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for Proximal Policy Optimization (PPO) training.\n","*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for plotting tools.\n","*   [`tarfile`](https://docs.python.org/3/library/tarfile.html/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for handling tar file operations.\n","*   [`pickle`](https://docs.python.org/3/library/pickle.html/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for serializing and deserializing Python objects.\n","*   [`json`](https://docs.python.org/3/library/json.html/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for parsing and writing JSON data.\n"]},{"cell_type":"markdown","id":"cd5de88f-7481-4be0-80e3-c0f18db61971","metadata":{},"source":["### Installing required libraries\n","\n","The following required libraries are __not__ preinstalled in the Skills Network Labs environment. __You must run the following cell__ to install them:\n","\n","**Note:** The version has been pinned to specify the version. It's recommended that you do this as well. Even if the library is updated in the future, the installed library could still support this lab work.\n","\n","This might take approximately 1 minute. \n"]},{"cell_type":"code","execution_count":null,"id":"8b877a18-dfe9-4d25-a8c7-e10022c20e2c","metadata":{},"outputs":[],"source":["!pip install datasets trl==0.11.0\n","!pip install --upgrade typing_extensions\n","!pip install matplotlib"]},{"cell_type":"markdown","id":"e698b7d5-6273-42c4-9211-5988e15b91e6","metadata":{},"source":["### Importing required libraries\n","\n","_It is recommended that you import all required libraries in one place (here):_\n"]},{"cell_type":"code","execution_count":null,"id":"55712b15-37a6-40b2-ad19-17fac5d2be29","metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"id":"98a7f011-175b-4d0b-b7ec-03b35b4fabdc","metadata":{},"outputs":[],"source":["import torch\n","from tqdm import tqdm\n","import pandas as pd\n","\n","tqdm.pandas()\n","\n","from transformers import pipeline, AutoTokenizer,AutoModelForCausalLM\n","from datasets import load_dataset\n","\n","from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n","from trl.core import LengthSampler\n","import os\n","\n","import tarfile\n","import pickle\n","import json\n","import matplotlib.pyplot as plt\n","import torch\n","import pandas as pd\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","# Disable warnings for a cleaner notebook or console experience\n","def warn(*args, **kwargs):\n","    pass\n","warnings.warn = warn"]},{"cell_type":"markdown","id":"f022b4e6-d0d4-413a-84c2-f466b3a9f7c6","metadata":{},"source":["## Defining helper functions\n"]},{"cell_type":"code","execution_count":4,"id":"1416a2d1-deb9-4a1c-8881-d3d9c8e7af31","metadata":{},"outputs":[],"source":["def save_to_json(data, file_path):\n","    \"\"\"\n","    Save a dictionary to a JSON file.\n","\n","    Args:\n","        data (dict): The dictionary to save.\n","        file_path (str): The path to the JSON file.\n","    \"\"\"\n","    with open(file_path, 'w') as json_file:\n","        json.dump(data, json_file, indent=4)\n","    print(f\"Data successfully saved to {file_path}\")\n","    \n","    \n","def load_from_json(file_path):\n","    \"\"\"\n","    Load data from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        dict: The data loaded from the JSON file.\n","    \"\"\"\n","    with open(file_path, 'r') as json_file:\n","        data = json.load(json_file)\n","    return data   \n"]},{"cell_type":"code","execution_count":5,"id":"c0d8f2fa-2224-43fa-a62e-72537e6d04de","metadata":{},"outputs":[],"source":["def pad_sequence_to_length(tensor, length, pad_token_id):\n","    padding_length = length - tensor.size(0)\n","    if padding_length > 0:\n","        padding = torch.full((padding_length,), pad_token_id, dtype=torch.long, device=tensor.device)\n","        return torch.cat((tensor, padding))\n","    return tensor\n","\n","def pad_list_to_batch_size(tensors, batch_size, pad_token_id):\n","    max_length = max(t.size(0) for t in tensors)\n","    padded_tensors = [pad_sequence_to_length(t, max_length, pad_token_id) for t in tensors]\n","\n","    # Add additional padding-only tensors if needed\n","    while len(padded_tensors) < batch_size:\n","        padded_tensors.append(torch.full((max_length,), pad_token_id, dtype=torch.long, device=tensors[0].device))\n","\n","    return padded_tensors[:batch_size]"]},{"cell_type":"code","execution_count":6,"id":"88b82a8a-75fb-4c24-afda-006235958e38","metadata":{},"outputs":[],"source":["def print_ppo_stats(stats, related_to_objective=False):\n","    print(\"PPO Training Statistics\\n\")\n","\n","    if related_to_objective:\n","        print(\"Objective Statistics:\")\n","        print(f\"  KL Divergence (objective/kl): {stats['objective/kl']}\")\n","        print(f\"  KL Coefficient (objective/kl_coef): {stats['objective/kl_coef']}\")\n","        print(f\"  Entropy (objective/entropy): {stats['objective/entropy']}\\n\")\n","        \n","        print(\"PPO Losses (Related to Minimizing Objective Function):\")\n","        print(f\"  Policy Loss (ppo/loss/policy): {stats['ppo/loss/policy']}\")\n","        print(f\"  Value Loss (ppo/loss/value): {stats['ppo/loss/value']}\")\n","        print(f\"  Total Loss (ppo/loss/total): {stats['ppo/loss/total']}\\n\")\n","        \n","        print(\"PPO Policy Statistics:\")\n","        print(f\"  Policy Entropy (ppo/policy/entropy): {stats['ppo/policy/entropy']}\")\n","        print(f\"  Approx KL (ppo/policy/approxkl): {stats['ppo/policy/approxkl']}\")\n","        print(f\"  Clip Fraction (ppo/policy/clipfrac): {stats['ppo/policy/clipfrac']}\\n\")\n","    else:\n","        print(\"Reward and Value Function Estimation:\")\n","        print(f\"  Mean Non-Score Reward (ppo/mean_non_score_reward): {stats['ppo/mean_non_score_reward']}\")\n","        print(f\"  Mean Scores (ppo/mean_scores): {stats['ppo/mean_scores']}\")\n","        print(f\"  Std Scores (ppo/std_scores): {stats['ppo/std_scores']}\")\n","        print(f\"  Value Prediction (ppo/val/vpred): {stats['ppo/val/vpred']}\")\n","        print(f\"  Value Prediction Error (ppo/val/error): {stats['ppo/val/error']}\")\n","        print(f\"  Value Prediction Variance (ppo/val/var): {stats['ppo/val/var']}\")\n","        print(f\"  Value Prediction Mean (ppo/val/mean): {stats['ppo/val/mean']}\")\n","        print(f\"  Explained Variance (ppo/val/var_explained): {stats['ppo/val/var_explained']}\\n\")\n","    \n","    print(\"Token Lengths:\")\n","    print(f\"  Queries Length Mean (tokens/queries_len_mean): {stats['tokens/queries_len_mean']}\")\n","    print(f\"  Responses Length Mean (tokens/responses_len_mean): {stats['tokens/responses_len_mean']}\\n\")\n","    \n","    print(\"Time Statistics:\")\n","    print(f\"  Total Time (time/ppo/total): {stats['time/ppo/total']} seconds\\n\")\n","\n","# Example usage with the provided stats and the flag"]},{"cell_type":"markdown","id":"7d4d7cab-21a8-476f-8e0a-84de711226a2","metadata":{},"source":["## Initializing the PPO configuration, model, and tokenizer\n"]},{"cell_type":"markdown","id":"e2a18bbd-903c-47e0-ba52-2c107aa38bb0","metadata":{},"source":["The `PPOConfig` class is used to specify the model and learning rate for the PPO training. In this case, the model is `\"lvwerra/gpt2-imdb\"` and the learning rate is set to `1.41e-5`.\n"]},{"cell_type":"code","execution_count":7,"id":"7ae0b3e8-2abd-4431-9b18-4143ff4a9caf","metadata":{},"outputs":[],"source":["config = PPOConfig(\n","    model_name=\"lvwerra/gpt2-imdb\",\n","    learning_rate=1.41e-5)"]},{"cell_type":"markdown","id":"23af07c8-c2cd-488e-ab42-ef42aee6da30","metadata":{},"source":["Please ignore above warning as the trl version you installed supports this module.\n"]},{"cell_type":"markdown","id":"eb642fff-cae5-4be8-b843-373a38a0bba1","metadata":{},"source":["`config.model_name` refers to the specific model identifier used in the configuration for loading the pretrained model. It specifies which model to load from the Hugging Face model repository. In this case, `config.model_name` is set to `\"lvwerra/gpt2-imdb\"`, indicating that the GPT-2 model fine-tuned on the IMDB dataset (by user lvwerra) should be used. This identifier is essential for loading the correct model architecture and weights during the fine-tuning or inference process.\n"]},{"cell_type":"code","execution_count":8,"id":"16355ae2-8b3e-45b2-a6c6-9ccd9a7de2bd","metadata":{},"outputs":[{"data":{"text/plain":["'lvwerra/gpt2-imdb'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["config.model_name"]},{"cell_type":"markdown","id":"aa7929d1-74e0-440c-9501-d3c25e7fd940","metadata":{},"source":["The `sent_kwargs` dictionary contains parameters for the sentiment analysis pipeline, specifying that all scores should be returned, the function to apply is `\"none\"`, and the batch size is `2`.\n","python\n"]},{"cell_type":"code","execution_count":9,"id":"442b9ed8-a608-4eb5-a06c-93151ecac6cd","metadata":{},"outputs":[],"source":["sent_kwargs = {\"top_k\":None, \"function_to_apply\": \"none\", \"batch_size\": 2}"]},{"cell_type":"markdown","id":"5896589e-bdac-4c5c-985b-6e4231fb06fd","metadata":{},"source":["The `AutoModelForCausalLMWithValueHead` class is used to load the pretrained GPT-2 model with a value head for PPO training. The model is loaded from the specified model name in the configuration.\n","\n","The `AutoTokenizer` class is used to load the tokenizer corresponding to the pretrained model. The tokenizer's padding token is set to the end-of-sequence (EOS) token.\n"]},{"cell_type":"code","execution_count":10,"id":"ac076dec-3081-4591-a0a9-9fe76c04771e","metadata":{},"outputs":[],"source":["model_1 = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n","\n","tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"markdown","id":"6ea11b0f-fa66-4849-92b6-8b69731173e3","metadata":{},"source":["Please ignore above warning as the trl version you installed handles it automatically.\n"]},{"cell_type":"code","execution_count":11,"id":"5d8bd5bc-0a0c-4006-8c19-6b1dec380de6","metadata":{},"outputs":[],"source":["# first model\n","model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)"]},{"cell_type":"markdown","id":"b7a425bc-9284-459b-b00b-c9c65a710411","metadata":{},"source":["During PPO training, update the model. In addition, the reference model is used to stabilize the model using the Kullback-Leibler (KL) divergence between the current policy and the reference policy.The KL divergence acts as a regularization term.\n"]},{"cell_type":"code","execution_count":12,"id":"2f7fefca-2987-4281-883c-67c6d0e65674","metadata":{},"outputs":[],"source":["ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)"]},{"cell_type":"markdown","id":"292a3a31-a02b-44f0-ae4f-12da60b3cbb6","metadata":{},"source":["## Dataset and dataset tokenization\n","\n","**Dataset Name:** IMDB\n","\n","**Description:** The IMDB dataset is a collection of 50,000 movie reviews labeled as \"positive\" or \"negative,\" indicating the sentiment of each review. This dataset is commonly used for sentiment analysis tasks.\n","\n","**Loading the Dataset:**\n","The dataset is loaded using the `load_dataset` function from the `datasets` library, specifically loading the \"train\" split.\n"]},{"cell_type":"code","execution_count":13,"id":"d2d592c1-2d7d-492d-b013-7dca69ef3a82","metadata":{},"outputs":[],"source":["dataset_name = \"imdb\"\n","ds = load_dataset(dataset_name, split = \"train\")"]},{"cell_type":"code","execution_count":14,"id":"2bdc430c-9e9d-4eaa-bf96-5bd4f4734eef","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["text I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n","label 0\n","text \"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n","label 0\n","text If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\n","label 0\n","text This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.\n","label 0\n","text Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that old Peggy Lee song..<br /><br />\"Is that all there is??\" ...I was just an early teen when this smoked fish hit the U.S. I was too young to get in the theater (although I did manage to sneak into \"Goodbye Columbus\"). Then a screening at a local film museum beckoned - Finally I could see this film, except now I was as old as my parents were when they schlepped to see it!!<br /><br />The ONLY reason this film was not condemned to the anonymous sands of time was because of the obscenity case sparked by its U.S. release. MILLIONS of people flocked to this stinker, thinking they were going to see a sex film...Instead, they got lots of closeups of gnarly, repulsive Swedes, on-street interviews in bland shopping malls, asinie political pretension...and feeble who-cares simulated sex scenes with saggy, pale actors.<br /><br />Cultural icon, holy grail, historic artifact..whatever this thing was, shred it, burn it, then stuff the ashes in a lead box!<br /><br />Elite esthetes still scrape to find value in its boring pseudo revolutionary political spewings..But if it weren't for the censorship scandal, it would have been ignored, then forgotten.<br /><br />Instead, the \"I Am Blank, Blank\" rhythymed title was repeated endlessly for years as a titilation for porno films (I am Curious, Lavender - for gay films, I Am Curious, Black - for blaxploitation films, etc..) and every ten years or so the thing rises from the dead, to be viewed by a new generation of suckers who want to see that \"naughty sex film\" that \"revolutionized the film industry\"...<br /><br />Yeesh, avoid like the plague..Or if you MUST see it - rent the video and fast forward to the \"dirty\" parts, just to get it over with.<br /><br />\n","label 0\n"]}],"source":["N = 5\n","for sample in range(N):\n","    print('text',ds[sample]['text'])\n","    print('label',ds[sample]['label'])"]},{"cell_type":"markdown","id":"d1a1412a-1683-404e-9f25-981068b4deab","metadata":{},"source":[" Rename the column \"text\" to \"review\"\n"]},{"cell_type":"code","execution_count":15,"id":"ef63e285-9c5a-47e3-a96b-b8ce6cfa70fe","metadata":{},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['review', 'label'],\n","    num_rows: 25000\n","})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["ds = ds.rename_columns({\"text\": \"review\"})\n","ds"]},{"cell_type":"markdown","id":"e2c41254-f0ed-40e4-8c25-17f557fde642","metadata":{},"source":["The dataset is filtered to include only reviews that are longer than 200 characters.\n"]},{"cell_type":"code","execution_count":16,"id":"6077e3fa-5fc0-4f56-a929-0a82cc423101","metadata":{},"outputs":[],"source":["ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)"]},{"cell_type":"markdown","id":"131ac431-53d9-4c62-9792-ccc79be3672c","metadata":{},"source":["Using a ```LengthSampler``` to sample different text lengths during data processing introduces variability, making the model more robust and capable of handling varying input lengths in real-world scenarios. This approach prevents overfitting by exposing the model to diverse input sizes, improving generalization to new data. It also ensures efficient training by managing the length of text inputs, maintaining practicality and performance. Overall, LengthSampler enhances model adaptability and effectiveness by simulating realistic, varied training conditions. Where sample length is between ```input_min_text_length``` and ```input_max_text_length```\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":17,"id":"8c527f34-f704-4616-b47d-41c4854f27f2","metadata":{},"outputs":[],"source":["input_min_text_length, input_max_text_length = 2, 8"]},{"cell_type":"markdown","id":"8eb18090-b79c-4f05-b775-ef55dc807844","metadata":{},"source":["Create a ```LengthSampler``` object\n"]},{"cell_type":"code","execution_count":18,"id":"ad1bb996-50f0-4990-bc62-7c1009f2e82d","metadata":{},"outputs":[{"data":{"text/plain":["<trl.core.LengthSampler at 0x7f2994d9cfb0>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["input_size = LengthSampler(input_min_text_length, input_max_text_length)\n","input_size"]},{"cell_type":"markdown","id":"8c56b712-eafb-40c7-bdbb-b55a94352614","metadata":{},"source":["This code uses the input_size object, an instance of ```LengthSampler```, to sample and print a random text length between 2 and 8 for each of 10 iterations.\"\n"]},{"cell_type":"code","execution_count":19,"id":"78672e60-b00e-4bcd-af63-40bb6f5fc018","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["sample 0 has length 7\n","\n","sample 1 has length 7\n","\n","sample 2 has length 6\n","\n","sample 3 has length 5\n","\n","sample 4 has length 3\n","\n","sample 5 has length 5\n","\n","sample 6 has length 3\n","\n","sample 7 has length 2\n","\n","sample 8 has length 2\n","\n","sample 9 has length 2\n","\n"]}],"source":["for i in range(10):\n","    size=input_size()\n","    print(f\"sample {i} has length {size}\\n\")"]},{"cell_type":"markdown","id":"c2da8722-1785-43b4-8cb6-6aec8662fcc9","metadata":{},"source":["Finally, you will need to sample tokens and obtain tokenized indexes. Let's verify this process with one sample.\n"]},{"cell_type":"code","execution_count":20,"id":"1b0fb347-ef2e-4bdd-a229-91f950f2f019","metadata":{},"outputs":[{"data":{"text/plain":["{'review': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n"," 'label': 0}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["sample=ds[0]\n","sample"]},{"cell_type":"markdown","id":"248a84d9-c06f-4c6b-8cf4-707bbe90459c","metadata":{},"source":["Next, tokenize the ```review``` text into input IDs, truncate the tokenized sequence to the desired length, and assign it to ```input_ids```\n"]},{"cell_type":"code","execution_count":21,"id":"1c7e5dbf-0655-4088-88ca-31b938a1b43a","metadata":{},"outputs":[{"data":{"text/plain":["[40, 26399, 314]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n","sample[\"input_ids\"]"]},{"cell_type":"markdown","id":"000ca0ad-a883-46ad-ba0f-39d507b2dc1d","metadata":{},"source":["Decode the truncated input IDs back into text and assign it to 'query', this is a will need the raw text for the reward fuction.\n"]},{"cell_type":"code","execution_count":22,"id":"6f4c0366-83ac-4ed4-bd39-a4782c5e4a21","metadata":{},"outputs":[{"data":{"text/plain":["'I rented I'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n","sample[\"query\"] "]},{"cell_type":"markdown","id":"4c399c0a-39ca-4ebc-892a-861f8bda66bc","metadata":{},"source":["In this function, combine the process of tokenizing the 'review' text, truncating it to the desired length, and decoding it back to text. This allows you to apply it to the dataset.\n"]},{"cell_type":"code","execution_count":23,"id":"f0f4ccf1-fd13-4c49-9258-9a978b1c28c8","metadata":{},"outputs":[],"source":["def tokenize(sample):\n","    sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n","    sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n","    return sample"]},{"cell_type":"markdown","id":"ddec2117-8792-4199-ba94-f81f0e929ff8","metadata":{},"source":["You can apply ```tokenize``` function to the dataset\n"]},{"cell_type":"code","execution_count":24,"id":"ba0eab58-a9b7-46c6-bde6-bb0ea0d682d5","metadata":{},"outputs":[],"source":["ds = ds.map(tokenize, batched=False)\n","ds.set_format(type=\"torch\")"]},{"cell_type":"markdown","id":"fbc015cf-7c4b-42bc-8279-34b626c176d5","metadata":{},"source":[">Note: you can safely ignore the above warning.\n","You can see the sample before and after:\n"]},{"cell_type":"code","execution_count":25,"id":"6fb78525-d79d-4f86-95af-89e010f8d26b","metadata":{},"outputs":[{"data":{"text/plain":["{'review': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n"," 'label': tensor(0),\n"," 'input_ids': tensor([   40, 26399,   314,  3001,   327]),\n"," 'query': 'I rented I AM C'}"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["ds[0]"]},{"cell_type":"markdown","id":"eae4ab07-258f-48cc-9365-9ba4979a7fa0","metadata":{},"source":["You can now iterate over the dataset, printing the first 5 samples with their 'review' and the added 'input_ids', and 'query' :\n"]},{"cell_type":"code","execution_count":26,"id":"8540249a-1780-400d-bb0c-985135912975","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample 1:\n","Review: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n","Input IDs: tensor([   40, 26399,   314,  3001,   327])\n","Query: I rented I AM C\n","--------------------------------------------------\n","Sample 2:\n","Review: \"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n","Input IDs: tensor([   1,   40, 1703])\n","Query: \"I Am\n","--------------------------------------------------\n","Sample 3:\n","Review: If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\n","Input IDs: tensor([1532,  691,  284, 3368, 1642])\n","Query: If only to avoid making\n","--------------------------------------------------\n","Sample 4:\n","Review: This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.\n","Input IDs: tensor([1212, 2646,  373, 2192, 7867,  416])\n","Query: This film was probably inspired by\n","--------------------------------------------------\n","Sample 5:\n","Review: Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that old Peggy Lee song..<br /><br />\"Is that all there is??\" ...I was just an early teen when this smoked fish hit the U.S. I was too young to get in the theater (although I did manage to sneak into \"Goodbye Columbus\"). Then a screening at a local film museum beckoned - Finally I could see this film, except now I was as old as my parents were when they schlepped to see it!!<br /><br />The ONLY reason this film was not condemned to the anonymous sands of time was because of the obscenity case sparked by its U.S. release. MILLIONS of people flocked to this stinker, thinking they were going to see a sex film...Instead, they got lots of closeups of gnarly, repulsive Swedes, on-street interviews in bland shopping malls, asinie political pretension...and feeble who-cares simulated sex scenes with saggy, pale actors.<br /><br />Cultural icon, holy grail, historic artifact..whatever this thing was, shred it, burn it, then stuff the ashes in a lead box!<br /><br />Elite esthetes still scrape to find value in its boring pseudo revolutionary political spewings..But if it weren't for the censorship scandal, it would have been ignored, then forgotten.<br /><br />Instead, the \"I Am Blank, Blank\" rhythymed title was repeated endlessly for years as a titilation for porno films (I am Curious, Lavender - for gay films, I Am Curious, Black - for blaxploitation films, etc..) and every ten years or so the thing rises from the dead, to be viewed by a new generation of suckers who want to see that \"naughty sex film\" that \"revolutionized the film industry\"...<br /><br />Yeesh, avoid like the plague..Or if you MUST see it - rent the video and fast forward to the \"dirty\" parts, just to get it over with.<br /><br />\n","Input IDs: tensor([5812,   11])\n","Query: Oh,\n","--------------------------------------------------\n"]}],"source":["for i, sample in enumerate(ds):\n","    if i >= 5:\n","        break\n","    print(f\"Sample {i+1}:\")\n","    print(f\"Review: {sample['review']}\")\n","    print(f\"Input IDs: {sample['input_ids']}\")\n","    print(f\"Query: {sample['query']}\")\n","    print(\"-\" * 50)"]},{"cell_type":"markdown","id":"58362a74-6e21-4cf2-8643-329816a3c103","metadata":{},"source":["The ```build_dataset``` function incorporates the necessary steps to build a dataset object for use as an input to ```PPOTrainer```. You will then reinstantiate the dataset object.\n"]},{"cell_type":"code","execution_count":27,"id":"f6fd45e5-9009-4aca-9d29-58273b6f8a5f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n","Found the latest cached dataset configuration 'plain_text' at /home/mcastrol/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Thu Dec 12 19:32:32 2024).\n"]}],"source":["del(ds)\n","dataset_name=\"imdb\"\n","ds = load_dataset(dataset_name, split=\"train\")\n","ds = ds.rename_columns({\"text\": \"review\"})"]},{"cell_type":"code","execution_count":28,"id":"325da9dd-15eb-4260-9741-bd978741feb4","metadata":{},"outputs":[],"source":["def build_dataset(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8,tokenizer=tokenizer):\n","    \"\"\"\n","    Build dataset for training. This builds the dataset from `load_dataset`, one should\n","    customize this function to train the model on its own dataset.\n","\n","    Args:\n","        dataset_name (`str`):\n","            The name of the dataset to be loaded.\n","\n","    Returns:\n","        dataloader (`torch.utils.data.DataLoader`):\n","            The dataloader for the dataset.\n","    \"\"\"\n","    \n","    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n","    tokenizer.pad_token = tokenizer.eos_token\n","    # load imdb with datasets\n","    ds = load_dataset(dataset_name, split=\"train\")\n","    ds = ds.rename_columns({\"text\": \"review\"})\n","    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n","\n","    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n","\n","    def tokenize(sample):\n","        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n","        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n","        return sample\n","\n","    ds = ds.map(tokenize, batched=False)\n","    ds.set_format(type=\"torch\")\n","    return ds"]},{"cell_type":"markdown","id":"d9d46bac-5f22-430b-b397-089032e2ebbf","metadata":{},"source":["Create the dataset object \n"]},{"cell_type":"code","execution_count":29,"id":"e3b64595-e95c-4d24-9319-05137579cce9","metadata":{},"outputs":[],"source":["dataset = build_dataset(config)"]},{"cell_type":"markdown","id":"0a6fb77f-7b10-4e89-82f7-03bbff085d7d","metadata":{},"source":["You can see each sample has ```input_ids``` and  ```query```\n"]},{"cell_type":"code","execution_count":30,"id":"8fe91981-dcdb-42fa-8d22-33051d09c10e","metadata":{},"outputs":[{"data":{"text/plain":["{'review': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n"," 'label': tensor(0),\n"," 'input_ids': tensor([   40, 26399,   314,  3001,   327, 47269, 20958]),\n"," 'query': 'I rented I AM CURIOUS'}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["dataset[0]"]},{"cell_type":"markdown","id":"f8d33349-0681-49fd-8ea1-c4d90861e4ff","metadata":{},"source":["## Collator function \n","The collator function is crucial for preparing data batches in a format suitable for the PPOTrainer. It ensures that each feature from the data samples is grouped together,\n"]},{"cell_type":"code","execution_count":31,"id":"136ac01d-b593-4a6f-956d-640bb87bbe2d","metadata":{},"outputs":[],"source":["def collator(data):\n","    return dict((key, [d[key] for d in data]) for key in data[0])"]},{"cell_type":"markdown","id":"94f24cd9-1083-42f8-89e7-7d8f409c2981","metadata":{},"source":["The collator function is best understood with an example. You can input two samples each with 'input_ids', 'query', and 'review'.\n"]},{"cell_type":"code","execution_count":32,"id":"45443d80-4df6-4a06-a260-2d6e50549a45","metadata":{},"outputs":[],"source":["data = [\n","    {'input_ids': [1, 2, 3, 4], 'query': \"sample text\", 'review': \"This is a sample review.\"},\n","    {'input_ids': [5, 6, 7, 8], 'query': \"another sample\", 'review': \"Another sample review.\"}\n","]"]},{"cell_type":"markdown","id":"72c99608-6262-44bc-9423-c9d8b69e126e","metadata":{},"source":["Apply the collator function to the above data\n"]},{"cell_type":"code","execution_count":33,"id":"d923d3ee-06f8-4ec2-83fc-06b931f45adb","metadata":{},"outputs":[{"data":{"text/plain":["{'input_ids': [[1, 2, 3, 4], [5, 6, 7, 8]],\n"," 'query': ['sample text', 'another sample'],\n"," 'review': ['This is a sample review.', 'Another sample review.']}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["batch = collator(data)\n","batch"]},{"cell_type":"markdown","id":"65f5d3ef-afd7-4dc3-898a-3d4ba7da3554","metadata":{},"source":["Now, 'input_ids', 'query', and 'review' each have their corresponding samples.\n"]},{"cell_type":"markdown","id":"1cb112de-43a0-4bfe-83d8-906a7ce2a06f","metadata":{},"source":["##  Initialize PPOTrainer \n","\n","Proximal Policy Optimization (PPO) is a reinforcement learning algorithm that is particularly well-suited for training generative models, including those used for chatbots. It helps address specific challenges in training these models, such as maintaining coherent and contextually appropriate dialogues.\n","\n","Proximal Policy Optimization (PPO) improves policy gradient methods for chatbots by using a clipped objective function, which ensures gradual and stable policy updates. This helps maintain consistent dialogue quality. Traditional policy gradient methods can lead to high variance and instability, resulting in inconsistent chatbot behavior. PPO's trust region balances exploring new responses and exploiting known good ones, making it more reliable for training chatbots. \n","\n","The PPO Trainer collects dialogue samples, optimizes the chatbot's policy based on these samples, and manages the neural network models. This ensures stable and efficient training, leading to high-quality, coherent, and contextually appropriate chatbot responses. \n","\n","Lets Initialize PPOTrainer with specified configuration and components\n"]},{"cell_type":"markdown","id":"8a5c49b9-e3a1-4718-a7f1-fabbc2d6cd1e","metadata":{},"source":["```config``` : Configuration settings for PPO training, such as learning rate and model name\n","\n","```model``` : The primary model to be fine-tuned using PPO\n","\n","```tokenizer```:Tokenizer corresponding to the model, used for processing input text\n","\n","```dataset```:  Dataset to be used for training, providing the input data for the model\n","\n","```data_collator```: Data collator to handle batching and formatting of the input data\n"]},{"cell_type":"code","execution_count":34,"id":"5eeb4de6-04f1-4d61-b20a-47ddb2ca14a5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ppo_trainer object  <trl.trainer.ppo_trainer.PPOTrainer object at 0x7f29945dea20>\n"]}],"source":["ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)\n","print(\"ppo_trainer object \",ppo_trainer)"]},{"cell_type":"markdown","id":"ed37dedf-470b-4fe6-9958-b9972048e96e","metadata":{},"source":["Please ignore above warnings as the trl version you installed supports this module.\n"]},{"cell_type":"markdown","id":"2240184b-7ade-4cc2-a5bb-e6cf92f3a8bf","metadata":{},"source":["Determine the appropriate device (CPU or GPU) for training with the PPO Trainer.\n"]},{"cell_type":"code","execution_count":35,"id":"cbc09e52-1b81-4676-b6da-909b5c800ac6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["device = ppo_trainer.accelerator.device\n","if ppo_trainer.accelerator.num_processes == 1:\n","    device = 0 if torch.cuda.is_available() else \"cpu\"  \n","print(device)"]},{"cell_type":"markdown","id":"5429e69a-23c9-48e0-8a58-c0f54059d7a1","metadata":{},"source":["## Reward function\n","\n","In reinforcement learning with PPO (Proximal Policy Optimization), a reward function is used to provide feedback on the quality of the actions taken by the policy. For a generative model like a chatbot, the reward function can evaluate the quality of the generated responses. Here’s how the sentiment analysis pipeline can be used as a reward function:\n","\n","In reinforcement learning with PPO, the sentiment analysis pipeline serves as a reward function to evaluate a chatbot's responses. By analyzing the sentiment of each response and assigning a reward based on the sentiment score, the PPO Trainer can optimize the chatbot’s policy to generate more positively received and engaging responses. This approach leverages sentiment analysis to provide meaningful feedback, guiding the chatbot towards improved performance in dialogue generation. Although not a typical reward model, it allows you to train the chatbot in a simple and effective way.\n"]},{"cell_type":"markdown","id":"0178127b-8053-4ab1-ba41-d72fb0c138f0","metadata":{},"source":["First, let's initialize a sentiment analysis pipeline using a pretrained model fine-tuned on IMDB reviews.\n","The model predicts the sentiment of text inputs, providing scores for positive and negative sentiments.\n"]},{"cell_type":"code","execution_count":36,"id":"9ca607b6-6a9a-4961-a70f-a2079e0711d0","metadata":{},"outputs":[],"source":["sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device)"]},{"cell_type":"markdown","id":"60a79772-2635-4d8f-8603-41691203518c","metadata":{},"source":["You'll get the sentiment value as negative here.\n"]},{"cell_type":"code","execution_count":37,"id":"b4089d11-f613-482f-a7c1-cfabe88d41a7","metadata":{},"outputs":[{"data":{"text/plain":["[{'label': 'NEGATIVE', 'score': 2.3350484371185303},\n"," {'label': 'POSITIVE', 'score': -2.726576328277588}]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["text = \"this movie was really bad!!\"\n","sentiment_pipe(text, **sent_kwargs)"]},{"cell_type":"markdown","id":"70aa802b-baa7-4d61-a573-657d70705067","metadata":{},"source":["The `score` key represents the model's confidence in its prediction. Higher score values indicate greater confidence in the sentiment classification, such as \"POSITIVE\" or \"NEGATIVE\". Thus, the value for `POSITIVE` class can be used to determine the reward values. For example, a high score for \"POSITIVE\" means the model is confident, which can increase rewards. Conversely, if the model isn’t confident that a review is positive, it results in a negative reward, lowering the total reward. This means negative sentiment reviews decrease the overall reward, while positive ones increase it.\n"]},{"cell_type":"code","execution_count":38,"id":"80a2af12-f894-4f90-bc12-88bd41360753","metadata":{},"outputs":[{"data":{"text/plain":["[{'label': 'POSITIVE', 'score': 2.557039976119995},\n"," {'label': 'NEGATIVE', 'score': -2.294790267944336}]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["text = \"this movie was really good!!\"\n","sentiment_pipe(text, **sent_kwargs)"]},{"cell_type":"markdown","id":"2e2ade1e-44df-48f5-bfb8-4a0e9d14afea","metadata":{},"source":["## Generating responses using PPO \n","\n","### Tokenizing and preparing the input batch\n","This section of code demonstrates how to generate responses using the PPO (Proximal Policy Optimization) Trainer. The process involves tokenizing the input, preparing the batch for training, generating responses, and decoding the generated tokens into readable text.\n"]},{"cell_type":"markdown","id":"6ed1e439-9e3d-408a-b9b2-3aa6da8eeb67","metadata":{},"source":["The code first retrieves a batch of data from the PPO Trainer's dataloader and selects the first two entries for processing.\n"]},{"cell_type":"code","execution_count":39,"id":"b1e13a8f-1e16-452b-b383-5b7de73f031b","metadata":{},"outputs":[],"source":["batch = next(iter(ppo_trainer.dataloader))"]},{"cell_type":"markdown","id":"a626e3f1-ad5f-4b1e-9a06-e732180f351e","metadata":{},"source":["The batch contains ```label```, ```input_ids```, and ```query```\n"]},{"cell_type":"code","execution_count":40,"id":"f3a4e5a5-2052-4c93-866e-c3c28fad9e8e","metadata":{},"outputs":[{"data":{"text/plain":["dict_keys(['label', 'input_ids', 'query'])"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["batch.keys()"]},{"cell_type":"markdown","id":"6009768d-2924-4c6d-935c-570f488d7d19","metadata":{},"source":["Now let's create a new batch containing only the first two samples from the original batch \n"]},{"cell_type":"code","execution_count":41,"id":"1790a597-ad72-41f9-ac59-05bd59600257","metadata":{},"outputs":[{"data":{"text/plain":["{'label': [tensor(0), tensor(0)],\n"," 'input_ids': [tensor([19197,   645]),\n","  tensor([1212, 3807,  373, 7818,   13,  383,  717])],\n"," 'query': ['Pay no', 'This movie was terrible. The first']}"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Let's take the first two  sample in the batch\n","batch = {key: batch[key][0:2] for key in batch}\n","batch"]},{"cell_type":"markdown","id":"2afa4f9b-e883-428e-b4e6-4cca13f894ef","metadata":{},"source":["Initialize a list of  ```response_tensors``` to store the responses for scoring\n"]},{"cell_type":"code","execution_count":42,"id":"c0331de0-5132-4b9c-b38e-3022f265a656","metadata":{},"outputs":[],"source":["response_tensors = []"]},{"cell_type":"markdown","id":"c1084832-48a2-4919-a60c-b9ff52189896","metadata":{},"source":["The below code extracts the `input_ids` from the `batch` and assigns them to `query_tensors`. These tensors represent the tokenized input sequences that will be used in the subsequent steps. They are called \"query tensors\" because they represent the initial input queries that will be processed by the model to generate responses.\n"]},{"cell_type":"code","execution_count":43,"id":"7381832a-d379-43f9-97a6-129fd319e54c","metadata":{},"outputs":[{"data":{"text/plain":["[tensor([19197,   645]), tensor([1212, 3807,  373, 7818,   13,  383,  717])]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["query_tensors =  batch[\"input_ids\"]\n","query_tensors"]},{"cell_type":"markdown","id":"af9ff495-6b4c-4be8-8ac2-a0336c0c5c6f","metadata":{},"source":["The below code defines a lambda function `get_text` that takes a list of responses (`response`) and decodes each tensor in the list using the tokenizer, converting the tensor back to readable text. The `squeeze()` method is used to remove any dimensions of size 1 from the tensor.\n"]},{"cell_type":"code","execution_count":44,"id":"5c01492d-6763-4298-b1cc-0b41c294ed26","metadata":{},"outputs":[],"source":["get_text = lambda response:''.join([tokenizer.decode(r.squeeze()) for r in response])"]},{"cell_type":"markdown","id":"52521848-e338-474d-bb62-aa91e2f4f342","metadata":{},"source":["You can see the original input queries in their text form.\n"]},{"cell_type":"code","execution_count":45,"id":"e2c670a8-578e-4355-a8db-52ff6318b8d1","metadata":{},"outputs":[{"data":{"text/plain":["'Pay noThis movie was terrible. The first'"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["get_text(query_tensors)"]},{"cell_type":"markdown","id":"dba91f75-064c-46b4-a828-3afc085a654b","metadata":{},"source":["\n","\n","The dictionary `generation_kwargs` sets the parameters for generating a sequence from the LLM (Language Model). The parameters include:\n","- `\"min_length\": -1` - No minimum length for the generated text.\n","- `\"top_k\": 0.0` - No filtering of the top-k most probable tokens.\n","- `\"top_p\": 1.0` - No nucleus sampling, using the entire distribution.\n","- `\"do_sample\": True` - Enables sampling, allowing for varied responses.\n","- `\"pad_token_id\": 50256` - ID of the padding token, ensuring uniform length across sequences.\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":47,"id":"181a23d1-12eb-4660-a0bb-6179c915474c","metadata":{},"outputs":[{"data":{"text/plain":["{'min_length': -1,\n"," 'top_k': 0.0,\n"," 'top_p': 1.0,\n"," 'do_sample': True,\n"," 'pad_token_id': 50256}"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["generation_kwargs = {\n","    \"min_length\": -1,\n","    \"top_k\": 0.0,\n","    \"top_p\": 1.0,\n","    \"do_sample\": True,\n","    \"pad_token_id\": 50256,\n","}\n","generation_kwargs"]},{"cell_type":"markdown","id":"06aa77d1-2a14-4742-9bf9-07ee417a6061","metadata":{},"source":["The `output_length_sampler` is initialized with `LengthSampler(output_min_length, output_max_length)`. This object is used to sample output lengths for the generated sequences, ensuring they fall within the specified minimum and maximum length range. By varying the lengths, you can produce more diverse and natural outputs from the language model, preventing the generation of overly short or excessively long sequences and enhancing the overall quality of the responses.\n"]},{"cell_type":"code","execution_count":48,"id":"be288af2-fb14-4c85-b3f7-cfe9a51ec4fe","metadata":{},"outputs":[],"source":["output_min_length = 4\n","output_max_length = 16\n","output_length_sampler = LengthSampler(output_min_length, output_max_length)"]},{"cell_type":"markdown","id":"482f107e-50c7-457d-b0b5-91ee423a8c63","metadata":{},"source":["The code calls the `output_length_sampler` to determine a length for the generated sequences. The sampled length is then stored in the variable `gen_len`.\n"]},{"cell_type":"code","execution_count":49,"id":"f68d437a-0c26-4813-9e76-0630eccb24d8","metadata":{},"outputs":[{"data":{"text/plain":["9"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["gen_len = output_length_sampler()\n","gen_len "]},{"cell_type":"markdown","id":"b9b0ea9a-5bd6-432d-bfd4-a10a58d9bf1c","metadata":{},"source":["Next, set the `max_new_tokens` parameter in the `generation_kwargs` dictionary to the value of `gen_len`, which was sampled from `output_length_sampler`. This ensures that the maximum number of new tokens generated by the language model is within the desired length range, promoting more controlled and appropriately lengthened responses.\n"]},{"cell_type":"code","execution_count":50,"id":"ed057893-a414-4573-bcea-41891675c8f0","metadata":{},"outputs":[{"data":{"text/plain":["{'min_length': -1,\n"," 'top_k': 0.0,\n"," 'top_p': 1.0,\n"," 'do_sample': True,\n"," 'pad_token_id': 50256,\n"," 'max_new_tokens': 9}"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["generation_kwargs[\"max_new_tokens\"] = gen_len\n","generation_kwargs"]},{"cell_type":"markdown","id":"f592c3ad-3728-4bce-bdbe-c0a343bab397","metadata":{},"source":["Now, let's process one sample using PPO. Start by extracting the first query tensor.\n"]},{"cell_type":"code","execution_count":51,"id":"c3d511de-0a3a-496a-9fdf-70fac331d44d","metadata":{},"outputs":[{"data":{"text/plain":["tensor([19197,   645])"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["query=query_tensors[0]\n","query"]},{"cell_type":"markdown","id":"cac60ce3-6f57-4078-87d9-9e9e2f1b9892","metadata":{},"source":["Lets generate a response for the extracted query using the PPO trainer with the specified generation parameters (generation_kwargs). The generated response tensor is stored in ```response```.\n"]},{"cell_type":"code","execution_count":52,"id":"b1d992bc-2638-4481-a1a8-b813e1d02d4a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"data":{"text/plain":["tensor([[19197,   645,  2392,   804,   588,   257,  1029, 10938,  8234, 29847,\n","          1671]])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["response = ppo_trainer.generate(query, **generation_kwargs)\n","response "]},{"cell_type":"markdown","id":"89dfff76-e809-4742-b4fc-b58c6b415935","metadata":{},"source":[">Note: You can safely ignore the above warning\n","\n","You can print the decoded text of the query and response tensors using the get_text function, converting the generated response back into a human-readable format. This demonstrates how the model has appended some text to the original query.\n"]},{"cell_type":"code","execution_count":53,"id":"29401adf-cde2-4f05-9e94-ece6547dbfbb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["query: Pay no\n","response: Pay no longer look like a high hanging fruit.<br\n"]}],"source":["print(\"query:\",get_text(query))\n","print(\"response:\", get_text(response))"]},{"cell_type":"markdown","id":"22db51be-62f1-48d9-8fa6-65948e090328","metadata":{},"source":["Finally, append the tokens of the  ```response_tensors``` list. The ```squeeze()``` method removes any single-dimensional entries from the shape of the tensor, and the slicing``` [-gen_len:]``` ensures only the newly generated tokens are included, ignoring any preceding tokens.\n"]},{"cell_type":"code","execution_count":54,"id":"d70e078d-576e-4833-a24c-363f86f5aad2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["newly generated tokens form response:  longer look like a high hanging fruit.<br\n"]}],"source":["response_tensors.append(response.squeeze()[-gen_len:])\n","print(\"newly generated tokens form response:\", get_text(response_tensors[-gen_len:]))"]},{"cell_type":"markdown","id":"c55dc7c0-1f3e-4f3d-b238-c7d08da77fd9","metadata":{},"source":["Repeat the process for the second sample. This section generates a response for a given query, decodes the relevant part, and appends it to the `response_tensors` list.\n"]},{"cell_type":"code","execution_count":55,"id":"bed67012-8d5d-4a7b-a063-7588abd91343","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["query: This movie was terrible. The first\n","response ouput :  longer look like a high hanging fruit.<br\n","newly generated tokens form response:  longer look like a high hanging fruit.<br movie was not bad\n"]}],"source":["query=query_tensors[1]\n","gen_len = output_length_sampler()\n","generation_kwargs[\"max_new_tokens\"] = gen_len\n","response = ppo_trainer.generate(query, **generation_kwargs)\n","tokenizer.decode(response.squeeze()[-gen_len:], skip_special_tokens=True)\n","print(\"query:\",get_text(query))\n","print(\"response ouput :\", get_text(response_tensors))\n","response_tensors.append(response.squeeze()[-gen_len:])\n","print(\"newly generated tokens form response:\", get_text(response_tensors[-gen_len:]))"]},{"cell_type":"markdown","id":"87b17db1-f52a-4592-b994-398abe627445","metadata":{},"source":["Convert each tensor in `response_tensors` into human-readable text and store it in the `batch` dictionary under the key `response`.\n"]},{"cell_type":"code","execution_count":56,"id":"3668ca65-6c8b-402e-a80d-641e91702f57","metadata":{},"outputs":[{"data":{"text/plain":["[' longer look like a high hanging fruit.<br', ' movie was not bad']"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n","batch[\"response\"]"]},{"cell_type":"markdown","id":"97789c0a-abdc-4b3f-bec9-e37b657f478f","metadata":{},"source":["The batch now contains both `response` and `query` keys.\n"]},{"cell_type":"code","execution_count":57,"id":"89a25d6b-51c0-4cae-9d22-e5d3340d2192","metadata":{},"outputs":[{"data":{"text/plain":["{'label': [tensor(0), tensor(0)],\n"," 'input_ids': [tensor([19197,   645]),\n","  tensor([1212, 3807,  373, 7818,   13,  383,  717])],\n"," 'query': ['Pay no', 'This movie was terrible. The first'],\n"," 'response': [' longer look like a high hanging fruit.<br',\n","  ' movie was not bad']}"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["batch"]},{"cell_type":"markdown","id":"2b7d9405-6b5c-44bf-b0ed-2cfe87a5e0ad","metadata":{},"source":["### Scoring function \n","\n","Next, prepare the text data for sentiment analysis, which can be a part of a reward function in a PPO setup where the sentiment analysis of interactions helps determine the reward.\n","\n","Now, extract the `query` and `response` tensors and add them to the batch.\n"]},{"cell_type":"code","execution_count":58,"id":"ec00c477-1a55-42fd-b614-61f406a5c3d0","metadata":{},"outputs":[{"data":{"text/plain":["['Pay no longer look like a high hanging fruit.<br',\n"," 'This movie was terrible. The first movie was not bad']"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n","texts"]},{"cell_type":"markdown","id":"3c928af5-0832-44ac-893e-7aa5623a6e6b","metadata":{},"source":["The sentiment scores (`pipe_outputs`) can be used as feedback to update the policy\n"]},{"cell_type":"code","execution_count":59,"id":"0a40cc33-fa35-45d9-87b3-041acbf286b7","metadata":{},"outputs":[{"data":{"text/plain":["[[{'label': 'NEGATIVE', 'score': 1.0307135581970215},\n","  {'label': 'POSITIVE', 'score': -1.395334243774414}],\n"," [{'label': 'NEGATIVE', 'score': 2.3252668380737305},\n","  {'label': 'POSITIVE', 'score': -2.7069687843322754}]]"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n","pipe_outputs"]},{"cell_type":"markdown","id":"b9ed7769-ec46-4fb8-9a90-a1d1156a1254","metadata":{},"source":["These scores can be used to evaluate the quality or relevance of the generated responses, indicating the model's confidence in the likelihood of the responses being positive. The scores for the generated responses are extracted from the `pipe_outputs` list. Each element in `pipe_outputs` contains a list of scores corresponding to the model's output.\n"]},{"cell_type":"markdown","id":"60d602e1-a127-460e-b52e-86ab7cbbdcf0","metadata":{},"source":["This line iterates over the `pipe_outputs` list, extracts the score from each output, converts it into a tensor, and stores it in the `rewards` list. The scores represent the model's confidence in the likelihood of the responses being positive sentences.\n"]},{"cell_type":"code","execution_count":60,"id":"a6552f76-da8a-4d93-a96b-2fd8b643527b","metadata":{},"outputs":[{"data":{"text/plain":["[tensor(-1.3953), tensor(-2.7070)]"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["positive_scores = [\n","    item[\"score\"]\n","    for output in pipe_outputs\n","    for item in output\n","    if item[\"label\"] == \"POSITIVE\"\n","]\n","rewards = [torch.tensor(score) for score in positive_scores]\n","rewards"]},{"cell_type":"markdown","id":"527a4e0a-efc4-41ae-9c9c-699e0b2eabef","metadata":{},"source":["### Proximal policy optimization \n","\n","The training loop is responsible for performing a single update step of the PPO algorithm. The inputs to this process are the query, response, and score tensors.\n"]},{"cell_type":"code","execution_count":61,"id":"f58912a8-c92f-4f68-b156-823311d766e6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["query: Pay noThis movie was terrible. The first\n","\n","\n","response:  longer look like a high hanging fruit.<br movie was not bad\n"]}],"source":["print(\"query:\", get_text(query_tensors))\n","print(\"\\n\")\n","print(\"response:\", get_text(response_tensors))"]},{"cell_type":"markdown","id":"514b887c-ddfc-446e-ad6c-09141c630729","metadata":{},"source":["To meet the PPO trainer's minimum batch size requirement of 128, you can pad the response tensors with additional sample.\n"]},{"cell_type":"code","execution_count":62,"id":"06d8e4ce-b4db-4273-9870-0b39e90c3b77","metadata":{},"outputs":[],"source":["batch_size=128\n","pad_token_id = tokenizer.pad_token_id\n","\n","query_tensors = pad_list_to_batch_size(query_tensors, batch_size, pad_token_id)\n","\n","response_tensors = pad_list_to_batch_size(response_tensors, batch_size, pad_token_id)\n","rewards=rewards+[torch.tensor(0) for _ in range(batch_size-len(rewards))]"]},{"cell_type":"markdown","id":"17dd6d05-0c4b-4185-aa0f-02328de4e35b","metadata":{},"source":["Now, call the PPO `step` method that updates the model using the PPO algorithm with `query_tensors`, `response_tensors`, and `rewards`.\n","\n","- It uses these inputs to calculate the policy and value function losses.\n","- It computes the gradients and updates the policy network parameters to improve the policy.\n","- It ensures that the policy update stays within a certain range to avoid large policy shifts, which is a core aspect of PPO.\n"]},{"cell_type":"markdown","id":"4449401c-235c-4527-8bfa-8fad22915496","metadata":{},"source":["*Note: The following code is commented out to prevent the kernel from crashing due to the absence of a GPU in the current environment. To execute this code, please download the notebook and run it in an environment equipped with a GPU. Simply uncomment the code before running it.*\n"]},{"cell_type":"code","execution_count":null,"id":"eb224749-ba07-4d4f-9246-27dc64317455","metadata":{},"outputs":[],"source":["# stats = ppo_trainer.step(query_tensors, response_tensors, rewards)"]},{"cell_type":"markdown","id":"19168b18-38d6-4575-a35e-ca0075d07dc9","metadata":{},"source":["The `stats` variable is a dictionary containing various statistics from the PPO training step. You can print out its keys using the function `print_ppo_stats`. These keys can be organized into two main categories:\n","\n","- **Minimizing the language model loss**: `related_to_objective=True`\n","  - This includes statistics related to optimizing the model parameters, such as policy loss and value loss.\n","\n","- **Calculating the reward**:\n","  - This involves metrics more relevant to reinforcement learning, such as advantage estimates and reward calculations.\n"]},{"cell_type":"code","execution_count":null,"id":"73232498-46aa-489a-a1e7-fea436ca979c","metadata":{},"outputs":[],"source":["# stats.keys()"]},{"cell_type":"code","execution_count":null,"id":"c97ea605-7ff5-4d4f-8a31-d58cd94e088a","metadata":{},"outputs":[],"source":["# print_ppo_stats(stats, related_to_objective = True)"]},{"cell_type":"code","execution_count":null,"id":"706ec7e0-d7ff-447a-ab8f-28062c0129e5","metadata":{},"outputs":[],"source":["# print_ppo_stats(stats)"]},{"cell_type":"code","execution_count":63,"id":"a875cf00-5d26-4592-bca4-2a6379a846b4","metadata":{},"outputs":[],"source":["all_stats = []"]},{"cell_type":"markdown","id":"7f38deb8-acc1-4e39-b0d8-f87d94ddd876","metadata":{},"source":["The `sentiment`should be set to NEGATIVE for bad responses and POSITIVE for good responses score .\n"]},{"cell_type":"code","execution_count":64,"id":"4c242aed-d45a-4b0a-ac9a-f365c10c6fbf","metadata":{},"outputs":[],"source":["sentiment = \"POSITIVE\""]},{"cell_type":"markdown","id":"5b6d9a76-0e88-41c3-b220-769bfbb5f25e","metadata":{},"source":["<!-- ### Training Loop for PPO with Sentiment Analysis -->\n","\n","This code snippet represents a training loop for the PPO (Proximal Policy Optimization) algorithm using sentiment analysis. The loop iterates over batches of data from the `ppo_trainer` dataloader and performs the following steps:\n","\n","1. **Extract query tensors**:\n","    - The input IDs (query tensors) are extracted from the batch.\n","\n","2. **Generate responses**:\n","    - For each query tensor, a response is generated using the `ppo_trainer.generate` method with the specified `generation_kwargs`.\n","    - The responses are then decoded and added to the batch under the `response` key.\n","\n","3. **Compute sentiment scores**:\n","    - Text data is prepared by concatenating queries and responses.\n","    - Sentiment analysis is performed on the combined texts to compute the sentiment scores.\n","    - The scores are converted into tensors and stored in the `rewards` list.\n","\n","4. **Run PPO step**:\n","    - The `ppo_trainer.step` method is called to update the model using the PPO algorithm with the `query_tensors`, `response_tensors`, and `rewards`.\n","    - This step calculates the policy and value function losses, computes gradients and updates the policy network parameters.\n","    - The policy update ensures it stays within a certain range to avoid large policy shifts.\n","\n","5. **Logging statistics**:\n","    - The statistics from the PPO training step are logged and stored in the `all_stats` list.\n","  \n","**Note:** Training the model on a CPU will be very time-consuming. You have pretrained the model using a GPU and saved it for your convenience. You can skip the training part and proceed to the next block of code and load the saved model. You can uncomment the below block of code to train the model yourself.\n"]},{"cell_type":"code","execution_count":null,"id":"6fdbff75-dc1f-4b99-b126-2e632bed56f7","metadata":{},"outputs":[],"source":["# for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n","#     query_tensors = batch[\"input_ids\"]\n","#     print(f\"epoch {epoch}\")\n","\n","#     #### Get response from gpt2\n","#     response_tensors = []\n","#     for query in query_tensors:\n","#         gen_len = output_length_sampler()\n","#         generation_kwargs[\"max_new_tokens\"] = gen_len\n","#         response = ppo_trainer.generate(query, **generation_kwargs)\n","#         response_tensors.append(response.squeeze()[-gen_len:])\n","#     batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n","\n","#     #### Compute sentiment score\n","#     texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n","#     pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n","#     positive_scores = [\n","#            item[\"score\"]\n","#            for output in pipe_outputs\n","#            for item in output\n","#            if item[\"label\"] == sentiment\n","#        ]\n","#    rewards = [torch.tensor(score) for score in positive_scores]\n","\n","#     #### Run PPO step\n","#     stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n","#     ppo_trainer.log_stats(stats, batch, rewards)\n","    \n","#     all_stats.append(stats)"]},{"cell_type":"code","execution_count":null,"id":"0833b542-d753-434d-aebe-d68ff34eeaf8","metadata":{},"outputs":[],"source":["# # Save the model\n","\n","# model_dir = \"ppo-good\"\n","# os.makedirs(model_dir, exist_ok=True)\n","\n","# # Save model configuration and weights\n","# model_1.save_pretrained(model_dir)\n","# tokenizer.save_pretrained(model_dir)"]},{"cell_type":"code","execution_count":65,"id":"33ef0ec1-1118-490a-a91f-7ecb21302714","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://cf-courses-data.s3.us.]\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           0% [>                             ]   15.22K    --.-KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           0% [>                             ]   32.00K  133.14KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           0% [>                             ]   64.00K  194.32KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           0% [>                             ]   95.31K  212.99KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           0% [>                             ]  142.27K  253.59KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           1% [>                             ]  237.93K  355.76KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           1% [>                             ]  363.17K  463.31KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           2% [>                             ]  598.00K  665.27KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           4% [>                             ]  975.65K  958.51KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           7% [=>                            ]    1.43M    1.26MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl           9% [=>                            ]    2.01M    1.59MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          13% [===>                          ]    2.75M    1.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          18% [====>                         ]    3.68M    2.44MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          23% [======>                       ]    4.83M    2.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          30% [========>                     ]    6.21M    3.53MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          37% [==========>                   ]    7.52M    4.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          44% [============>                 ]    9.04M    4.50MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          50% [==============>               ]   10.19M    4.78MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          56% [===============>              ]   11.45M    5.07MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          63% [==================>           ]   12.85M    5.40MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          71% [====================>         ]   14.38M    5.73MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          77% [======================>       ]   15.69M    5.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          83% [========================>     ]   16.85M    6.11MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          89% [=========================>    ]   18.15M    6.29MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl          96% [===========================>  ]   19.46M    6.75MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good.pkl         100% [=============================>]   20.21M    7.13MB/s\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 1  Bytes: 20.21M [4.08M]\u001b8\u001b[m\u001b[m\u001b[m\u001b[m\n","\n","\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://cf-courses-data.s3.us.]\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]   15.22K    --.-KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]   30.87K  125.24KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]   46.53K  125.24KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]   79.65K  171.82KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]  110.96K  191.10KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]  173.58K  252.97KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]  267.51K  335.94KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]  424.07K  466.72KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]  703.31K  687.40KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]    1.02M  920.63KB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]    1.43M    1.13MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]    1.96M    1.41MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]    2.60M    1.72MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        0% [>                             ]    3.48M    2.13MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        1% [>                             ]    4.57M    2.60MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        1% [>                             ]    5.87M    3.12MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        1% [>                             ]    7.12M    3.54MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        1% [>                             ]    8.27M    3.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        2% [>                             ]    9.72M    4.31MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        2% [>                             ]   10.88M    4.57MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        2% [>                             ]   12.13M    4.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        3% [>                             ]   13.35M    5.07MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        3% [>                             ]   14.66M    5.32MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        3% [>                             ]   15.87M    5.50MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        3% [>                             ]   17.15M    5.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        4% [>                             ]   18.36M    6.36MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        4% [>                             ]   19.69M    6.81MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        4% [>                             ]   20.83M    7.20MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        5% [>                             ]   22.10M    7.62MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        5% [>                             ]   23.50M    8.07MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        5% [>                             ]   24.74M    8.45MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        5% [>                             ]   25.93M    8.77MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        6% [>                             ]   27.01M    9.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        6% [>                             ]   28.41M    9.37MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        6% [=>                            ]   29.72M    9.64MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        6% [=>                            ]   30.91M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        7% [=>                            ]   32.16M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        7% [=>                            ]   33.54M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        7% [=>                            ]   34.71M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        8% [=>                            ]   35.87M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        8% [=>                            ]   37.05M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        8% [=>                            ]   38.54M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        8% [=>                            ]   39.60M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        9% [=>                            ]   40.87M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        9% [=>                            ]   42.17M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz        9% [=>                            ]   43.55M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       10% [==>                           ]   44.53M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       10% [==>                           ]   45.90M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       10% [==>                           ]   47.27M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       10% [==>                           ]   48.51M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       11% [==>                           ]   49.54M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       11% [==>                           ]   50.90M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       11% [==>                           ]   52.35M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       12% [==>                           ]   53.33M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       12% [==>                           ]   54.59M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       12% [==>                           ]   55.96M   10.05MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       12% [==>                           ]   57.34M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       13% [==>                           ]   58.15M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       13% [===>                          ]   59.68M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       13% [===>                          ]   60.96M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       14% [===>                          ]   62.20M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       14% [===>                          ]   63.18M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       14% [===>                          ]   64.65M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       14% [===>                          ]   66.02M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       15% [===>                          ]   66.83M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       15% [===>                          ]   68.34M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       15% [===>                          ]   69.57M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       16% [===>                          ]   70.98M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       16% [===>                          ]   71.86M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       16% [===>                          ]   73.43M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       16% [====>                         ]   74.69M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       17% [====>                         ]   75.83M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       17% [====>                         ]   76.79M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       17% [====>                         ]   78.46M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       18% [====>                         ]   79.74M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       18% [====>                         ]   80.78M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       18% [====>                         ]   81.89M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       18% [====>                         ]   83.35M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       19% [====>                         ]   84.71M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       19% [====>                         ]   85.75M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       19% [====>                         ]   86.96M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       19% [====>                         ]   88.35M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       20% [=====>                        ]   89.70M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       20% [=====>                        ]   90.66M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       20% [=====>                        ]   92.07M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       21% [=====>                        ]   93.41M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       21% [=====>                        ]   94.68M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       21% [=====>                        ]   95.60M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       21% [=====>                        ]   97.12M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       22% [=====>                        ]   98.55M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       22% [=====>                        ]   99.52M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       22% [=====>                        ]  100.51M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       23% [=====>                        ]  102.16M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       23% [======>                       ]  103.57M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       23% [======>                       ]  104.57M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       23% [======>                       ]  105.57M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       24% [======>                       ]  107.06M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       24% [======>                       ]  108.52M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       24% [======>                       ]  109.24M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       25% [======>                       ]  110.62M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       25% [======>                       ]  112.20M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       25% [======>                       ]  113.21M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       25% [======>                       ]  114.26M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       26% [======>                       ]  115.76M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       26% [======>                       ]  117.33M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       26% [=======>                      ]  118.08M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       26% [=======>                      ]  119.26M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       27% [=======>                      ]  120.90M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       27% [=======>                      ]  122.12M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       27% [=======>                      ]  123.08M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       28% [=======>                      ]  124.39M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       28% [=======>                      ]  125.90M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       28% [=======>                      ]  126.86M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       28% [=======>                      ]  128.14M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       29% [=======>                      ]  129.37M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       29% [=======>                      ]  130.71M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       29% [=======>                      ]  131.83M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       30% [========>                     ]  132.99M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       30% [========>                     ]  134.41M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       30% [========>                     ]  135.63M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       30% [========>                     ]  136.87M    9.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       31% [========>                     ]  138.10M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       31% [========>                     ]  139.54M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       31% [========>                     ]  140.61M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       32% [========>                     ]  141.84M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       32% [========>                     ]  143.22M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       32% [========>                     ]  144.54M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       32% [========>                     ]  145.60M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       33% [========>                     ]  147.02M   10.05MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       33% [=========>                    ]  148.16M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       33% [=========>                    ]  149.21M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       34% [=========>                    ]  150.57M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       34% [=========>                    ]  152.01M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       34% [=========>                    ]  153.17M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       34% [=========>                    ]  154.33M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       35% [=========>                    ]  155.70M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       35% [=========>                    ]  156.94M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       35% [=========>                    ]  158.02M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       36% [=========>                    ]  159.40M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       36% [=========>                    ]  160.71M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       36% [=========>                    ]  162.03M   10.08MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       36% [==========>                   ]  162.91M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       37% [==========>                   ]  164.54M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       37% [==========>                   ]  165.77M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       37% [==========>                   ]  166.80M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       38% [==========>                   ]  168.05M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       38% [==========>                   ]  169.46M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       38% [==========>                   ]  170.91M   10.10MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       38% [==========>                   ]  171.71M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       39% [==========>                   ]  173.13M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       39% [==========>                   ]  174.49M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       39% [==========>                   ]  175.63M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       39% [==========>                   ]  176.71M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       40% [===========>                  ]  178.26M   10.09MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       40% [===========>                  ]  179.55M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       40% [===========>                  ]  180.45M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       41% [===========>                  ]  181.77M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       41% [===========>                  ]  183.32M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       41% [===========>                  ]  184.60M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       41% [===========>                  ]  185.58M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       42% [===========>                  ]  186.88M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       42% [===========>                  ]  188.32M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       42% [===========>                  ]  189.40M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       43% [===========>                  ]  190.49M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       43% [============>                 ]  191.93M   10.07MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       43% [============>                 ]  193.32M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       43% [============>                 ]  194.23M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       44% [============>                 ]  195.59M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       44% [============>                 ]  197.02M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       44% [============>                 ]  197.97M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       45% [============>                 ]  199.26M    9.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       45% [============>                 ]  200.56M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       45% [============>                 ]  201.60M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       45% [============>                 ]  202.79M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       46% [============>                 ]  204.23M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       46% [============>                 ]  205.66M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       46% [=============>                ]  206.49M    9.80MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       47% [=============>                ]  207.87M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       47% [=============>                ]  209.29M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       47% [=============>                ]  210.11M    9.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       47% [=============>                ]  211.51M    9.79MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       48% [=============>                ]  212.93M    9.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       48% [=============>                ]  214.27M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       48% [=============>                ]  215.21M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       49% [=============>                ]  216.60M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       49% [=============>                ]  218.01M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       49% [=============>                ]  219.08M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       49% [=============>                ]  220.32M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       50% [==============>               ]  221.55M    9.80MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       50% [==============>               ]  222.98M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       50% [==============>               ]  224.02M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       50% [==============>               ]  225.30M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       51% [==============>               ]  226.68M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       51% [==============>               ]  228.01M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       51% [==============>               ]  229.04M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       52% [==============>               ]  230.35M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       52% [==============>               ]  231.79M   10.07MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       52% [==============>               ]  232.99M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       52% [==============>               ]  233.91M    9.81MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       53% [==============>               ]  235.30M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       53% [===============>              ]  236.84M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       53% [===============>              ]  237.51M    9.80MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       54% [===============>              ]  239.04M   10.05MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       54% [===============>              ]  240.43M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       54% [===============>              ]  241.18M    9.81MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       54% [===============>              ]  242.56M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       55% [===============>              ]  244.07M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       55% [===============>              ]  245.18M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       55% [===============>              ]  246.18M    9.78MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       56% [===============>              ]  247.55M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       56% [===============>              ]  249.11M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       56% [===============>              ]  250.02M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       56% [================>             ]  251.29M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       57% [================>             ]  252.66M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       57% [================>             ]  253.84M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       57% [================>             ]  254.89M    9.80MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       57% [================>             ]  256.34M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       58% [================>             ]  257.74M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       58% [================>             ]  258.71M    9.85MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       58% [================>             ]  259.93M    9.77MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       59% [================>             ]  261.24M    9.81MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       59% [================>             ]  262.48M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       59% [================>             ]  263.65M    9.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       59% [================>             ]  265.08M    9.81MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       60% [=================>            ]  266.29M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       60% [=================>            ]  267.49M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       60% [=================>            ]  268.63M    9.79MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       61% [=================>            ]  269.79M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       61% [=================>            ]  271.19M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       61% [=================>            ]  272.42M    9.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       61% [=================>            ]  273.68M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       62% [=================>            ]  274.88M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       62% [=================>            ]  276.15M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       62% [=================>            ]  277.37M    9.81MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       63% [=================>            ]  278.67M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       63% [=================>            ]  279.91M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       63% [==================>           ]  281.24M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       63% [==================>           ]  282.35M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       64% [==================>           ]  283.71M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       64% [==================>           ]  284.79M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       64% [==================>           ]  285.93M    9.79MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       64% [==================>           ]  287.31M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       65% [==================>           ]  288.60M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       65% [==================>           ]  289.90M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       65% [==================>           ]  291.07M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       66% [==================>           ]  292.43M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       66% [==================>           ]  293.48M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       66% [===================>          ]  294.82M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       66% [===================>          ]  296.00M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       67% [===================>          ]  297.23M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       67% [===================>          ]  298.46M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       67% [===================>          ]  299.75M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       68% [===================>          ]  301.05M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       68% [===================>          ]  302.16M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       68% [===================>          ]  303.52M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       68% [===================>          ]  304.71M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       69% [===================>          ]  305.82M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       69% [===================>          ]  307.10M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       69% [===================>          ]  308.52M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       70% [====================>         ]  309.71M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       70% [====================>         ]  310.77M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       70% [====================>         ]  312.19M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       70% [====================>         ]  313.55M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       71% [====================>         ]  314.52M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       71% [====================>         ]  315.80M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       71% [====================>         ]  317.27M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       72% [====================>         ]  318.43M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       72% [====================>         ]  319.46M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       72% [====================>         ]  320.90M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       72% [====================>         ]  322.32M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       73% [====================>         ]  323.20M    9.85MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       73% [=====================>        ]  324.60M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       73% [=====================>        ]  325.85M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       74% [=====================>        ]  327.13M    9.95MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       74% [=====================>        ]  328.21M    9.88MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       74% [=====================>        ]  329.54M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       74% [=====================>        ]  330.88M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       75% [=====================>        ]  332.08M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       75% [=====================>        ]  333.28M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       75% [=====================>        ]  334.58M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       75% [=====================>        ]  335.90M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       76% [=====================>        ]  337.02M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       76% [=====================>        ]  338.38M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       76% [======================>       ]  339.68M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       77% [======================>       ]  340.96M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       77% [======================>       ]  341.93M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       77% [======================>       ]  343.16M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       77% [======================>       ]  344.50M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       78% [======================>       ]  345.82M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       78% [======================>       ]  347.07M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       78% [======================>       ]  348.30M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       79% [======================>       ]  349.51M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       79% [======================>       ]  350.70M    9.85MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       79% [======================>       ]  352.12M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       79% [======================>       ]  353.19M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       80% [=======================>      ]  354.57M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       80% [=======================>      ]  355.76M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       80% [=======================>      ]  357.01M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       81% [=======================>      ]  358.13M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       81% [=======================>      ]  359.60M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       81% [=======================>      ]  360.82M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       81% [=======================>      ]  361.96M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       82% [=======================>      ]  363.21M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       82% [=======================>      ]  364.52M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       82% [=======================>      ]  365.96M   10.05MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       83% [=======================>      ]  366.94M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       83% [=======================>      ]  368.32M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       83% [========================>     ]  369.53M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       83% [========================>     ]  370.68M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       84% [========================>     ]  371.91M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       84% [========================>     ]  373.43M   10.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       84% [========================>     ]  374.56M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       84% [========================>     ]  375.62M    9.91MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       85% [========================>     ]  377.06M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       85% [========================>     ]  378.27M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       85% [========================>     ]  379.44M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       86% [========================>     ]  380.68M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       86% [========================>     ]  382.07M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       86% [=========================>    ]  383.34M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       86% [=========================>    ]  384.40M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       87% [=========================>    ]  385.65M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       87% [=========================>    ]  387.12M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       87% [=========================>    ]  388.21M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       88% [=========================>    ]  389.29M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       88% [=========================>    ]  390.68M    9.97MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       88% [=========================>    ]  392.17M   10.06MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       88% [=========================>    ]  393.10M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       89% [=========================>    ]  394.33M    9.85MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       89% [=========================>    ]  395.79M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       89% [=========================>    ]  396.93M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       90% [==========================>   ]  397.91M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       90% [==========================>   ]  399.25M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       90% [==========================>   ]  400.85M   10.05MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       90% [==========================>   ]  401.84M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       91% [==========================>   ]  402.99M    9.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       91% [==========================>   ]  404.41M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       91% [==========================>   ]  405.73M    9.96MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       91% [==========================>   ]  406.59M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       92% [==========================>   ]  407.94M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       92% [==========================>   ]  409.46M    9.99MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       92% [==========================>   ]  410.80M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       93% [==========================>   ]  411.67M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       93% [===========================>  ]  413.02M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       93% [===========================>  ]  414.54M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       93% [===========================>  ]  415.44M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       94% [===========================>  ]  416.79M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       94% [===========================>  ]  418.10M   10.00MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       94% [===========================>  ]  418.99M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       95% [===========================>  ]  420.40M    9.80MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       95% [===========================>  ]  421.67M    9.92MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       95% [===========================>  ]  423.19M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       95% [===========================>  ]  424.13M    9.84MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       96% [===========================>  ]  425.41M    9.89MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       96% [===========================>  ]  426.80M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       96% [============================> ]  427.87M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       97% [============================> ]  429.26M    9.86MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       97% [============================> ]  430.43M    9.93MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       97% [============================> ]  431.73M    9.98MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       97% [============================> ]  432.78M    9.85MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       98% [============================> ]  434.24M    9.90MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       98% [============================> ]  435.45M   10.02MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       98% [============================> ]  436.77M   10.01MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       99% [============================> ]  437.74M    9.82MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       99% [============================> ]  439.12M    9.83MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       99% [============================> ]  440.56M   10.03MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz       99% [============================> ]  441.65M    9.94MB/s\u001b8\u001b7\u001b[2A\u001b[1Gppo-good-tar.gz      100% [=============================>]  442.02M    9.88MB/s\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 1  Bytes: 442.02M [9.41]\u001b8\u001b[m\u001b[m\u001b[m\u001b[m"]}],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/gSWo8GeztngSmzHpqX_RaQ/ppo-good.pkl\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/we8t5N-45dVq3VhxGwYRAg/ppo-good-tar.gz"]},{"cell_type":"code","execution_count":66,"id":"8afd75ef-57de-4527-9238-017b767b6084","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Extraction completed.\n"]}],"source":["# File name\n","file_name = \"ppo-good-tar.gz\"\n","\n","# Open the tar.gz file\n","with tarfile.open(file_name, \"r:gz\") as tar:\n","    # Extract all the contents into the current directory\n","    tar.extractall()\n","\n","print(\"Extraction completed.\")"]},{"cell_type":"code","execution_count":null,"id":"64a5e039-038d-4e06-a721-328284a3d69f","metadata":{},"outputs":[],"source":["model_dir = \"ppov3new1\"\n","model_1 = AutoModelForCausalLMWithValueHead.from_pretrained(model_dir)\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","\n","# Load training stats\n","file_name = \"ppo-good.pkl\"\n","with open(file_name, 'rb') as f:\n","    all_stats = pickle.load(f)\n","\n","model_1.to(device)"]},{"cell_type":"markdown","id":"e78935bd-ddf7-4144-aa26-6c7265603033","metadata":{},"source":[">Note: You can safely ignore the above warning.\n"]},{"cell_type":"markdown","id":"3a5e930d-9c8e-42c7-97c7-348048977f9d","metadata":{},"source":["## Plotting PPO training loss and mean \n","\n","1. **Extracting values**:\n","    - `loss_values`: Total loss values from `all_stats`.\n","    - `reward_values`: Mean reward values from `all_stats`.\n","\n","2. **Plotting the loss**:\n","    - Line plot of total loss over epochs.\n","\n","3. **Plotting the rewards**:\n","    - Line plot of mean reward over epochs.\n","\n","4. **Displaying the plots**:\n","    - Arrange and show the plots using `plt.tight_layout()` and `plt.show()`.\n"]},{"cell_type":"code","execution_count":null,"id":"d1b242c5-c538-48b8-a0b3-588ae0193aa7","metadata":{},"outputs":[],"source":["loss_values = [stat['ppo/loss/total'] for stat in all_stats]\n","reward_values = [stat['ppo/mean_scores'] for stat in all_stats]\n","\n","# Plotting the loss\n","plt.figure(figsize=(12, 6))\n","plt.subplot(2, 1, 1)\n","plt.plot(loss_values, label='Total Loss', color='b')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('PPO Training Loss over Time')\n","plt.legend()\n","plt.grid(True)\n","\n","# Plotting the rewards\n","plt.subplot(2, 1, 2)\n","plt.plot(reward_values, label='Mean Reward', color='g')\n","plt.xlabel('Epoch')\n","plt.ylabel('Reward')\n","plt.title('PPO Mean Reward over Time')\n","plt.legend()\n","plt.grid(True)\n","\n","# Show the plots\n","plt.tight_layout()\n","plt.show()    "]},{"cell_type":"markdown","id":"ebcb5876-41a8-49b5-b2e2-3f9bd55f353c","metadata":{},"source":["## Generating and analyzing text with PPO and reference models\n","**Device Setup**:\n","    - Determine if CUDA is available and set the device accordingly.\n"]},{"cell_type":"code","execution_count":67,"id":"b004fa8b-53bc-4b8f-876d-e07bd455dadf","metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Set the pipeline device\n","pipeline_device = 0 if device.type == \"cuda\" else -1"]},{"cell_type":"markdown","id":"89ea1d5c-0475-4d51-82ab-86501f3aa75f","metadata":{},"source":["**Text generation function**:\n","    - `generate_some_text(input_text, my_model)`: Tokenizes input text, generates a response, and decodes it.\n"]},{"cell_type":"code","execution_count":68,"id":"2a7d6016-42e8-41a7-a1e7-c765d9ebb5c9","metadata":{},"outputs":[],"source":["gen_kwargs = {\"min_length\": -1, \"max_new_tokens\":20, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}\n","def generate_some_text(input_text,my_model):\n","# Tokenize the input text\n","    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n","    generated_ids = my_model.generate(input_ids,**gen_kwargs )\n","\n","    # Decode the generated text\n","    generated_text_ = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    return generated_text_"]},{"cell_type":"markdown","id":"ff6d7d93-2d15-4875-bdd1-ef8ad7b66bd9","metadata":{},"source":["**Generate text with PPO model**:\n","    - Generate text using the PPO-trained model.\n"]},{"cell_type":"code","execution_count":69,"id":"86fd5746-4bea-49a8-b5c2-d99d1e095826","metadata":{},"outputs":[{"data":{"text/plain":["\"Once upon a time in a land far left behind, I saw an aquarium I'd never seen before and was hurrying to stop to look\""]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["input_text = \"Once upon a time in a land far\"\n","\n","generated_text=generate_some_text(input_text,model_1)\n","generated_text"]},{"cell_type":"markdown","id":"33182fcc-77ce-4247-9ff0-9751adcb60d8","metadata":{},"source":["**Sentiment Analysis**:\n","    - Analyze the sentiment of the generated text using `sentiment_pipe`.\n"]},{"cell_type":"code","execution_count":null,"id":"49bbeb17-c169-4409-9f57-4d516bc2367d","metadata":{},"outputs":[],"source":["pipe_outputs = sentiment_pipe(generated_text, **sent_kwargs)\n","pipe_outputs"]},{"cell_type":"markdown","id":"fd9d51fa-bab2-4773-8054-ec4e9d151c23","metadata":{},"source":["**Generate text with reference model**:\n","    - Generate text using the reference model.\n"]},{"cell_type":"code","execution_count":null,"id":"feb68233-31ca-4dc6-a3c6-e1c6ebc87c40","metadata":{},"outputs":[],"source":["generated_text = generate_some_text(input_text,ref_model)\n","generated_text"]},{"cell_type":"markdown","id":"2fd7fb22-d2b0-443b-b939-682d3ad3ac0a","metadata":{},"source":["## Comparing PPO and reference models on \n","\n","1. **Generation Parameters**:\n","    - Define `gen_kwargs` for text generation.\n","\n","2. **Prepare Batch**:\n","    - Sample a batch of size `bs` from the dataset and extract query tensors.\n","\n","3. **Generate Responses**:\n","    - For each query tensor, generate responses using both the reference model and the PPO model.\n","\n","4. **Decode Responses**:\n","    - Decode the generated response tensors into human-readable text.\n","\n","5. **Compute Sentiment Scores**:\n","    - Prepare texts by concatenating queries and responses.\n","    - Compute sentiment scores for the responses before and after training using `sentiment_pipe`.\n","\n","6. **Store Results**:\n","    - Store queries, responses, and sentiment scores in `game_data`.\n","    - Convert `game_data` into a DataFrame and return it.\n"]},{"cell_type":"code","execution_count":70,"id":"dc202d59-2d5d-426a-a53d-a5c07e217aae","metadata":{},"outputs":[],"source":["def compare_models_on_dataset(model, ref_model, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler):\n","    gen_kwargs = {\n","        \"min_length\": -1, \n","        \"top_k\": 0.0, \n","        \"top_p\": 1.0, \n","        \"do_sample\": True, \n","        \"pad_token_id\": tokenizer.eos_token_id\n","    }\n","    \n","    bs = 16\n","    game_data = dict()\n","    dataset.set_format(\"pandas\")\n","    df_batch = dataset[:].sample(bs)\n","    game_data[\"query\"] = df_batch[\"query\"].tolist()\n","    query_tensors = df_batch[\"input_ids\"].tolist()\n","\n","    response_tensors_ref, response_tensors = [], []\n","\n","    # Get maximum position embeddings for both models\n","    max_position_embeddings_ref = ref_model.config.max_position_embeddings\n","    max_position_embeddings_model = model.config.max_position_embeddings\n","\n","    for i in range(bs):\n","        gen_len = output_length_sampler()\n","\n","        # Convert query tensors to input IDs\n","        input_ids = torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device)\n","\n","        # ********** Process for ref_model **********\n","        total_length_ref = input_ids.shape[-1] + gen_len\n","        if total_length_ref > max_position_embeddings_ref:\n","            # Truncate input_ids to fit within the max length\n","            max_input_length_ref = max_position_embeddings_ref - gen_len\n","            input_ids_ref = input_ids[:, -max_input_length_ref:]\n","            total_length_ref = input_ids_ref.shape[-1] + gen_len\n","        else:\n","            input_ids_ref = input_ids\n","        \n","        output = ref_model.generate(\n","            torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), \n","            max_new_tokens=gen_len, \n","            **gen_kwargs\n","        ).squeeze()[-gen_len:]\n","        response_tensors_ref.append(output)\n","\n","        # ********** Process for model **********\n","        total_length_model = input_ids.shape[-1] + gen_len\n","        if total_length_model > max_position_embeddings_model:\n","            max_input_length_model = max_position_embeddings_model - gen_len\n","            input_ids_model = input_ids[:, -max_input_length_model:]\n","            total_length_model = input_ids_model.shape[-1] + gen_len\n","        else:\n","            input_ids_model = input_ids\n","        \n","        output = model.generate(\n","            torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), \n","            max_new_tokens=gen_len, \n","            **gen_kwargs\n","        ).squeeze()[-gen_len:]\n","        response_tensors.append(output)\n","\n","    game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n","    game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n","\n","    texts_before = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n","    game_data[\"rewards (before)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts_before, **sent_kwargs)]\n","\n","    texts_after = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n","    game_data[\"rewards (after)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts_after, **sent_kwargs)]\n","\n","    df_results = pd.DataFrame(game_data)\n","    return df_results"]},{"cell_type":"code","execution_count":71,"id":"54abd8bd-8f03-40ba-83e3-abaa7eb5dcf0","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query</th>\n","      <th>response (before)</th>\n","      <th>response (after)</th>\n","      <th>rewards (before)</th>\n","      <th>rewards (after)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The movie deserves 2/10</td>\n","      <td>stars for being a reasonably well-done horror...</td>\n","      <td>The movie deserves 2/10 stars.&lt;|endoftext|&gt;</td>\n","      <td>-1.485119</td>\n","      <td>-0.905817</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>To say that</td>\n","      <td>Zakia cannot play in this kind of movie is to</td>\n","      <td>it is surprisingly successful with kids (and ...</td>\n","      <td>-2.140022</td>\n","      <td>-2.226216</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Why Panic never got a</td>\n","      <td>D+--this film mainly</td>\n","      <td>chance to emerge, I could</td>\n","      <td>-0.519017</td>\n","      <td>-0.041130</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Given the title and outlandish box</td>\n","      <td>office numbers taking place at which the film...</td>\n","      <td>art, the acting was simply dreadful, and to s...</td>\n","      <td>-2.387713</td>\n","      <td>-3.084659</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This is just the best movie</td>\n","      <td>I've seen in about ten years... even though t...</td>\n","      <td>I have seen this year. Some of the much bette...</td>\n","      <td>-2.402591</td>\n","      <td>-2.346875</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>As a community theater</td>\n","      <td>, its not a bad</td>\n","      <td>we've lived in,</td>\n","      <td>-1.092446</td>\n","      <td>-1.045124</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>A very ordinary made-for-</td>\n","      <td>TV film starring adults, and it's nothing like...</td>\n","      <td>TV-movie with awful dialog and annoying acting...</td>\n","      <td>-0.841202</td>\n","      <td>-2.925668</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Not on the same level</td>\n","      <td>as the rest of</td>\n","      <td>as The Matrix or</td>\n","      <td>-0.890810</td>\n","      <td>-1.250009</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>This is not</td>\n","      <td>about football but about politics</td>\n","      <td>to bad film. I</td>\n","      <td>-0.568884</td>\n","      <td>-1.275634</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Slas</td>\n","      <td>hers him and the rest of the cast</td>\n","      <td>hers sometimes turn bait, instruments feel washed</td>\n","      <td>-1.765422</td>\n","      <td>-1.584159</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Honestly, I</td>\n","      <td>can't believe people made this. I didn't like</td>\n","      <td>went a few levels above on the total BCI rating</td>\n","      <td>-2.111895</td>\n","      <td>-0.216460</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>I first saw</td>\n","      <td>this brilliant adaptation of the thriller and...</td>\n","      <td>the previews back in 1997, when I was about 1...</td>\n","      <td>-2.177594</td>\n","      <td>-0.945034</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Not since Calig</td>\n","      <td>ula in Invaders (1966) has</td>\n","      <td>ula's death, nor Hollywood's</td>\n","      <td>-0.182994</td>\n","      <td>-0.399768</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>This movie</td>\n","      <td>is worth your time - if that's the case but d...</td>\n","      <td>was honestly just better than anything a movi...</td>\n","      <td>-1.235657</td>\n","      <td>-1.791161</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Is this the</td>\n","      <td>'real' low-brow thing</td>\n","      <td>first FranMincey movie--</td>\n","      <td>-1.384990</td>\n","      <td>-1.378042</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>This movie appears</td>\n","      <td>to be proceeding normally when basing on the</td>\n","      <td>to be the first horror film with Mity</td>\n","      <td>-0.996014</td>\n","      <td>-0.886187</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 query  \\\n","0              The movie deserves 2/10   \n","1                          To say that   \n","2                Why Panic never got a   \n","3   Given the title and outlandish box   \n","4          This is just the best movie   \n","5               As a community theater   \n","6            A very ordinary made-for-   \n","7                Not on the same level   \n","8                          This is not   \n","9                                 Slas   \n","10                         Honestly, I   \n","11                         I first saw   \n","12                     Not since Calig   \n","13                          This movie   \n","14                         Is this the   \n","15                  This movie appears   \n","\n","                                    response (before)  \\\n","0    stars for being a reasonably well-done horror...   \n","1       Zakia cannot play in this kind of movie is to   \n","2                                D+--this film mainly   \n","3    office numbers taking place at which the film...   \n","4    I've seen in about ten years... even though t...   \n","5                                     , its not a bad   \n","6   TV film starring adults, and it's nothing like...   \n","7                                      as the rest of   \n","8                   about football but about politics   \n","9                   hers him and the rest of the cast   \n","10      can't believe people made this. I didn't like   \n","11   this brilliant adaptation of the thriller and...   \n","12                         ula in Invaders (1966) has   \n","13   is worth your time - if that's the case but d...   \n","14                              'real' low-brow thing   \n","15       to be proceeding normally when basing on the   \n","\n","                                     response (after)  rewards (before)  \\\n","0         The movie deserves 2/10 stars.<|endoftext|>         -1.485119   \n","1    it is surprisingly successful with kids (and ...         -2.140022   \n","2                           chance to emerge, I could         -0.519017   \n","3    art, the acting was simply dreadful, and to s...         -2.387713   \n","4    I have seen this year. Some of the much bette...         -2.402591   \n","5                                     we've lived in,         -1.092446   \n","6   TV-movie with awful dialog and annoying acting...         -0.841202   \n","7                                    as The Matrix or         -0.890810   \n","8                                      to bad film. I         -0.568884   \n","9   hers sometimes turn bait, instruments feel washed         -1.765422   \n","10    went a few levels above on the total BCI rating         -2.111895   \n","11   the previews back in 1997, when I was about 1...         -2.177594   \n","12                       ula's death, nor Hollywood's         -0.182994   \n","13   was honestly just better than anything a movi...         -1.235657   \n","14                           first FranMincey movie--         -1.384990   \n","15              to be the first horror film with Mity         -0.996014   \n","\n","    rewards (after)  \n","0         -0.905817  \n","1         -2.226216  \n","2         -0.041130  \n","3         -3.084659  \n","4         -2.346875  \n","5         -1.045124  \n","6         -2.925668  \n","7         -1.250009  \n","8         -1.275634  \n","9         -1.584159  \n","10        -0.216460  \n","11        -0.945034  \n","12        -0.399768  \n","13        -1.791161  \n","14        -1.378042  \n","15        -0.886187  "]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["df_results = compare_models_on_dataset(model_1, ref_model, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler)\n","df_results"]},{"cell_type":"markdown","id":"1327cc7b-d13d-4b10-824e-233ff37b7254","metadata":{},"source":["### Running the PPO model with negative sentiment\n","\n","This code runs the PPO training loop with the sentiment set to NEGATIVE, which evaluates the model's performance when negative sentiment scores are prioritized. The training loop generates responses, computes sentiment scores, updates the model, and logs the statistics for each epoch.\n"]},{"cell_type":"code","execution_count":72,"id":"040905c4-265a-4d11-a2b8-f610b2691f98","metadata":{},"outputs":[],"source":["sentiment = \"NEGATIVE\""]},{"cell_type":"code","execution_count":null,"id":"3ed201fd-7c6e-4fe7-81c9-854e29520e74","metadata":{},"outputs":[],"source":["# for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n","#     query_tensors = batch[\"input_ids\"]\n","#     print(f\"epoch {epoch}\")\n","\n","#     #### Get response from gpt2\n","#     response_tensors = []\n","#     for query in query_tensors:\n","#         gen_len = output_length_sampler()\n","#         generation_kwargs[\"max_new_tokens\"] = gen_len\n","#         response = ppo_trainer.generate(query, **generation_kwargs)\n","#         response_tensors.append(response.squeeze()[-gen_len:])\n","#     batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n","\n","#     #### Compute sentiment score\n","#     texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n","#     pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n","#     negative_scores = [\n","#            item[\"score\"]\n","#            for output in pipe_outputs\n","#            for item in output\n","#            if item[\"label\"] == sentiment\n","#        ]\n","#    rewards = [torch.tensor(score) for score in negative_scores]\n","\n","#     #### Run PPO step\n","#     stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n","#     ppo_trainer.log_stats(stats, batch, rewards)\n","    \n","#     all_stats.append(stats)"]},{"cell_type":"code","execution_count":null,"id":"960da1a1-4238-4e6d-8aaa-1dd1890cccc4","metadata":{},"outputs":[],"source":["# # Save the model\n","\n","# model_dir = \"ppo-bad\"\n","# os.makedirs(model_dir, exist_ok=True)\n","\n","# # Save model configuration and weights\n","# model_0.save_pretrained(model_dir)\n","# tokenizer.save_pretrained(model_dir)"]},{"cell_type":"markdown","id":"a362e426-50fd-47e8-af4a-b95a36dc093f","metadata":{},"source":["**Note:** Training the model on a CPU will be very time-consuming. The model has been pretrained using a GPU and saved for your convenience. You can skip the training part, proceed to the next block of code, and load the saved model. You can also uncomment the above training block of code to train the model yourself.\n"]},{"cell_type":"code","execution_count":null,"id":"ed4975a0-c2cb-4319-b518-d36438f4b931","metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/8zCp__SHRSgGVlf5yP50Ag/ppo-bad-tar.gz\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/jMW99Z9mvxesgYR-H6y6Yw/ppo-bad.pkl"]},{"cell_type":"code","execution_count":null,"id":"a2c8cc22-beb4-4d97-9936-97a3388f19f6","metadata":{},"outputs":[],"source":["import tarfile\n","# File name\n","file_name = \"ppo-bad-tar.gz\"\n","\n","# Open the tar.gz file\n","with tarfile.open(file_name, \"r:gz\") as tar:\n","    # Extract all the contents into the current directory\n","    tar.extractall()\n","\n","print(\"Extraction completed.\")"]},{"cell_type":"code","execution_count":null,"id":"98a56491-b792-4abe-9201-4b55663f12e4","metadata":{},"outputs":[],"source":["import tarfile\n","model_dir = \"ppov3new_bad1\"\n","model_0 = AutoModelForCausalLMWithValueHead.from_pretrained(model_dir)\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","\n","# Load training stats\n","file_name = \"ppo-bad.pkl\"\n","with open(file_name, 'rb') as f:\n","    all_stats = pickle.load(f)\n","\n","model_0.to(device)"]},{"cell_type":"markdown","id":"1a718322-17d2-474a-aae3-410f65fff43d","metadata":{},"source":[">Note: You can safely ignore the above warning.\n"]},{"cell_type":"markdown","id":"cc0207d8-b444-4894-a1b1-d44a4860bf0f","metadata":{},"source":["### Comparing models with negative sentiment\n","\n","The below code compares the performance of the PPO-trained model (`model_0`) and the reference model on the given dataset. The `compare_models_on_dataset` function generates responses from both models, computes their sentiment scores, and returns the results in a DataFrame (`df_results`). This comparison helps evaluate how well the PPO-trained model performs in generating positive responses when the `sentiment` is set to NEGATIVE.\n","\n","Since the dataset is fairly large, we will only use a subset of the dataset for testing.\n"]},{"cell_type":"code","execution_count":null,"id":"2dd31c8d-ac92-43e2-b0cd-193efe5f44d6","metadata":{},"outputs":[],"source":["df_results = compare_models_on_dataset(model_0, ref_model, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler)\n","df_results"]},{"cell_type":"markdown","id":"c75937a9-975d-4624-8776-02a1223eea16","metadata":{},"source":["### Exercise: Comparing PPO models\n","\n","In this exercise, you will compare the performance of two PPO-trained models (`model_0` and `model_1`) using the `compare_models_on_dataset` function and note the difference in performance of both.\n","\n","**Compare Models**:\n","   - Use the `compare_models_on_dataset` function to compare `model_0` and `model_1`.\n"]},{"cell_type":"code","execution_count":73,"id":"0b36c69e-ed0f-46e1-a60f-109471af841b","metadata":{},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","id":"3000ac58-64b5-450c-b921-95e0e815171b","metadata":{},"source":["<details>\n","    <summary>Click here for Solution</summary>\n","\n","```python\n","df_results = compare_models_on_dataset(model_0, model_1, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler)\n","df_results\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"61c890ee-566b-4894-a833-3c8bad26c817","metadata":{},"source":["## Authors\n","\n","[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo) has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n","\n","[Ashutosh Sagar](https://www.linkedin.com/in/ashutoshsagar/) is completing his MS in CS from Dalhousie University. He has previous experience working with Natural Language Processing and as a Data Scientist.\n"]},{"cell_type":"markdown","id":"9f73b232-7732-4015-9b3d-816cfa68f753","metadata":{},"source":["## Contributors\n","\n","[Hailey Quach](https://author.skills.network/instructors/hailey_quach) is a Data Scientist at IBM. She's completing her Bsc, Honors in Computer Science at Concordia University, Montreal.\n"]},{"cell_type":"markdown","id":"30f1f710-83ce-47ae-885b-059f78c23f8b","metadata":{},"source":["## References\n","\n","\n","[TEXT CLASSIFICATION WITH THE TORCHTEXT LIBRARY](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)\n","\n","[Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/pdf/1902.00751.pdf)\n","\n","[Simple, Scalable Adaptation for Neural Machine Translation](https://arxiv.org/pdf/1909.08478)\n"]},{"cell_type":"markdown","id":"66e70795-4fc7-446d-84ca-4567fb235057","metadata":{},"source":["```{## Change Log}\n","```\n"]},{"cell_type":"markdown","id":"4aabccb8-f64f-4f54-bcdc-b53ead7535d2","metadata":{},"source":["```{|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2024-06-27|0.1|Kang Wang|Create the lab|}\n","```\n"]},{"cell_type":"markdown","id":"bc808bd8-eaf5-490c-8e24-ef9caa2484c0","metadata":{},"source":["© Copyright IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"prev_pub_hash":"febcb0ff319ab930e46d30d4d1bc1329ad2f8aa613c9a5ec96659fa44d3daf95"},"nbformat":4,"nbformat_minor":4}
